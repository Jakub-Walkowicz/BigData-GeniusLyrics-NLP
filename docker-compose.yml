services:
  cassandra:
    container_name: cassandra
    hostname: cassandra
    image: cassandra:latest
    ports:
      - "9042:9042"
    env_file:
      - docker/cassandra/cassandra.env
    volumes:
      - ./infrastructure/cassandra:/var/lib/cassandra
    healthcheck:
      test: [ "CMD-SHELL", "cqlsh -e 'describe keyspaces'" ]
      interval: 10s
      timeout: 5s
      retries: 10
    restart: always

  spark-master:
    container_name: spark-master
    hostname: spark-master
    build:
      context: .
      dockerfile: ./docker/spark/Dockerfile
    env_file:
      - docker/spark/master.env
    ports:
      - '8080:8080'
      - '7077:7077'
    healthcheck:
      test: [ "CMD-SHELL", "timeout 5s bash -c '< /dev/tcp/localhost/8080'" ]
      interval: 10s
      timeout: 5s
      retries: 3
    volumes:
      - .:/opt/spark/work-dir
    command: /opt/spark/bin/spark-class org.apache.spark.deploy.master.Master

  spark-worker:
    container_name: spark-worker
    hostname: spark-worker
    build:
      context: .
      dockerfile: ./docker/spark/Dockerfile
    env_file:
      - docker/spark/worker.env
    depends_on:
      spark-master:
        condition: service_healthy
      cassandra:
        condition: service_healthy
    volumes:
      - .:/opt/spark/work-dir
    command: /opt/spark/bin/spark-class org.apache.spark.deploy.worker.Worker spark://spark-master:7077

  jupyter:
    container_name: jupyter
    build:
      context: .
      dockerfile: ./docker/spark/Dockerfile
    user: root
    ports: [ "8888:8888" ]
    volumes: [ ".:/opt/spark/work-dir" ]
    command: jupyter lab --ip=0.0.0.0 --port=8888 --no-browser --allow-root --NotebookApp.token=''